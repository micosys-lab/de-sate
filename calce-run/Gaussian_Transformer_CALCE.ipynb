{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL_HEfse5EQ-"
      },
      "source": [
        "Reference:\n",
        "\n",
        "D. Chen, W. Hong and X. Zhou, \"Transformer Network for Remaining Useful Life Prediction of Lithium-Ion Batteries,\" in IEEE Access, vol. 10, pp. 19621-19628, 2022."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/XiuzeZhou/RUL.git\n",
        "!mv RUL/datasets .\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vfCmfPfF5GCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3YDS4WW5ERD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "%matplotlib inline\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9riDHfQ5ERF"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEPUdEz55ERF"
      },
      "outputs": [],
      "source": [
        "def drop_outlier(array,count,bins):\n",
        "    index = []\n",
        "    range_ = np.arange(1,count,bins)\n",
        "    for i in range_[:-1]:\n",
        "        array_lim = array[i:i+bins]\n",
        "        sigma = np.std(array_lim)\n",
        "        mean = np.mean(array_lim)\n",
        "        th_max,th_min = mean + sigma*2, mean - sigma*2\n",
        "        idx = np.where((array_lim < th_max) & (array_lim > th_min))\n",
        "        idx = idx[0] + i\n",
        "        index.extend(list(idx))\n",
        "    return np.array(index)\n",
        "\n",
        "\n",
        "def build_sequences(text, window_size):\n",
        "    #text:list of capacity\n",
        "    x, y = [],[]\n",
        "    for i in range(len(text) - window_size):\n",
        "        sequence = text[i:i+window_size]\n",
        "        target = text[i+1:i+1+window_size]\n",
        "\n",
        "        x.append(sequence)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "# leave-one-out evaluation: one battery is sampled randomly; the remainder are used for training.\n",
        "def get_train_test(data_dict, name, window_size=8):\n",
        "    data_sequence=data_dict[name]['capacity']\n",
        "    train_data, test_data = data_sequence[:window_size+1], data_sequence[window_size+1:]\n",
        "    train_x, train_y = build_sequences(text=train_data, window_size=window_size)\n",
        "    for k, v in data_dict.items():\n",
        "        if k != name:\n",
        "            data_x, data_y = build_sequences(text=v['capacity'], window_size=window_size)\n",
        "            train_x, train_y = np.r_[train_x, data_x], np.r_[train_y, data_y]\n",
        "\n",
        "    return train_x, train_y, list(train_data), list(test_data)\n",
        "\n",
        "\n",
        "def relative_error(y_test, y_predict, threshold):\n",
        "    true_re, pred_re = len(y_test), 0\n",
        "    for i in range(len(y_test)-1):\n",
        "        if y_test[i] <= threshold >= y_test[i+1]:\n",
        "            true_re = i - 1\n",
        "            break\n",
        "    for i in range(len(y_predict)-1):\n",
        "        if y_predict[i] <= threshold:\n",
        "            pred_re = i - 1\n",
        "            break\n",
        "    return abs(true_re - pred_re)/true_re if abs(true_re - pred_re)/true_re<=1 else 1\n",
        "\n",
        "\n",
        "def evaluation(y_test, y_predict):\n",
        "    mse = mean_squared_error(y_test, y_predict)\n",
        "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
        "    return rmse\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttUxf3fN5ERH"
      },
      "outputs": [],
      "source": [
        "Battery_list = ['CS2_35', 'CS2_36', 'CS2_37', 'CS2_38']\n",
        "\n",
        "dir_path = 'datasets/CALCE/'\n",
        "Battery = {}\n",
        "for name in Battery_list:\n",
        "    print('Load Dataset ' + name + ' ...')\n",
        "    path = glob.glob(dir_path + name + '/*.xlsx')\n",
        "    dates = []\n",
        "    for p in path:\n",
        "        df = pd.read_excel(p, sheet_name=1)\n",
        "        print('Load ' + str(p) + ' ...')\n",
        "        dates.append(df['Date_Time'][0])\n",
        "    idx = np.argsort(dates)\n",
        "    path_sorted = np.array(path)[idx]\n",
        "\n",
        "    count = 0\n",
        "    discharge_capacities = []\n",
        "    health_indicator = []\n",
        "    internal_resistance = []\n",
        "    CCCT = []\n",
        "    CVCT = []\n",
        "    for p in path_sorted:\n",
        "        df = pd.read_excel(p,sheet_name=1)\n",
        "        print('Load ' + str(p) + ' ...')\n",
        "        cycles = list(set(df['Cycle_Index']))\n",
        "        for c in cycles:\n",
        "            df_lim = df[df['Cycle_Index'] == c]\n",
        "            #Charging\n",
        "            df_c = df_lim[(df_lim['Step_Index'] == 2)|(df_lim['Step_Index'] == 4)]\n",
        "            c_v = df_c['Voltage(V)']\n",
        "            c_c = df_c['Current(A)']\n",
        "            c_t = df_c['Test_Time(s)']\n",
        "            #CC or CV\n",
        "            df_cc = df_lim[df_lim['Step_Index'] == 2]\n",
        "            df_cv = df_lim[df_lim['Step_Index'] == 4]\n",
        "            CCCT.append(np.max(df_cc['Test_Time(s)'])-np.min(df_cc['Test_Time(s)']))\n",
        "            CVCT.append(np.max(df_cv['Test_Time(s)'])-np.min(df_cv['Test_Time(s)']))\n",
        "\n",
        "            #Discharging\n",
        "            df_d = df_lim[df_lim['Step_Index'] == 7]\n",
        "            d_v = df_d['Voltage(V)']\n",
        "            d_c = df_d['Current(A)']\n",
        "            d_t = df_d['Test_Time(s)']\n",
        "            d_im = df_d['Internal_Resistance(Ohm)']\n",
        "\n",
        "            if(len(list(d_c)) != 0):\n",
        "                time_diff = np.diff(list(d_t))\n",
        "                d_c = np.array(list(d_c))[1:]\n",
        "                discharge_capacity = time_diff*d_c/3600 # Q = A*h\n",
        "                discharge_capacity = [np.sum(discharge_capacity[:n]) for n in range(discharge_capacity.shape[0])]\n",
        "                discharge_capacities.append(-1*discharge_capacity[-1])\n",
        "\n",
        "                dec = np.abs(np.array(d_v) - 3.8)[1:]\n",
        "                start = np.array(discharge_capacity)[np.argmin(dec)]\n",
        "                dec = np.abs(np.array(d_v) - 3.4)[1:]\n",
        "                end = np.array(discharge_capacity)[np.argmin(dec)]\n",
        "                health_indicator.append(-1 * (end - start))\n",
        "\n",
        "                internal_resistance.append(np.mean(np.array(d_im)))\n",
        "                count += 1\n",
        "\n",
        "    discharge_capacities = np.array(discharge_capacities)\n",
        "    health_indicator = np.array(health_indicator)\n",
        "    internal_resistance = np.array(internal_resistance)\n",
        "    CCCT = np.array(CCCT)\n",
        "    CVCT = np.array(CVCT)\n",
        "\n",
        "    idx = drop_outlier(discharge_capacities, count, 40)\n",
        "    df_result = pd.DataFrame({'cycle':np.linspace(1,idx.shape[0],idx.shape[0]),\n",
        "                              'capacity':discharge_capacities[idx],\n",
        "                              'SoH':health_indicator[idx],\n",
        "                              'resistance':internal_resistance[idx],\n",
        "                              'CCCT':CCCT[idx],\n",
        "                              'CVCT':CVCT[idx]})\n",
        "    Battery[name] = df_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa1GchsP5ERK"
      },
      "source": [
        "### If the original data set cannot be read successfully, you can simply load the data I have extracted: CALCE.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilHmFVGy5ERK"
      },
      "outputs": [],
      "source": [
        "Battery_list = ['CS2_35', 'CS2_36', 'CS2_37', 'CS2_38']\n",
        "Battery = np.load('datasets/CALCE/CALCE.npy', allow_pickle=True)\n",
        "Battery = Battery.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPa-obQ95ERL"
      },
      "outputs": [],
      "source": [
        "# Rated_Capacity = 1.1\n",
        "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "color_list = ['b:', 'g--', 'r-.', 'c.']\n",
        "for name,color in zip(Battery_list, color_list):\n",
        "    df_result = Battery[name]\n",
        "    ax.plot(df_result['cycle'], df_result['capacity'], color, label='Battery_'+name)\n",
        "ax.set(xlabel='Discharge cycles', ylabel='Capacity (Ah)', title='Capacity degradation at ambient temperature of 1°C')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S17tZHw_5ERN"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size=16, hidden_dim=8, noise_level=0.01, noise_type='gaussian'):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.input_size, self.hidden_dim, self.noise_level, self.noise_type = input_size, hidden_dim, noise_level, noise_type\n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "        self.fc2 = nn.Linear(self.hidden_dim, self.input_size)\n",
        "\n",
        "    def noiser(self, x) :\n",
        "      random_x = torch.randn_like(x)\n",
        "\n",
        "      if self.noise_type == 'gaussian':\n",
        "        corrupted_x = x + self.noise_level * random_x\n",
        "        return corrupted_x\n",
        "      if self.noise_type == 'speckle':\n",
        "        corrupted_x = x * (1 + self.noise_level * random_x)\n",
        "        return corrupted_x\n",
        "      if self.noise_type == 'poisson':\n",
        "        # Apply Poisson noise\n",
        "        rate = torch.abs(x) / (self.noise_level + 1e-6)\n",
        "        corrupted_x = x + ((self.noise_level + 1e-6) * torch.poisson(rate))\n",
        "        return corrupted_x\n",
        "      if self.noise_type == 'uniform':\n",
        "        corrupted_x = x + self.noise_level * (random_x -0.5)\n",
        "        return corrupted_x\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = self.fc1(x)\n",
        "        h1 = F.relu(x)\n",
        "        return h1\n",
        "\n",
        "    def mask(self, x):\n",
        "        corrupted_x = x + self.noise_level * torch.randn_like(x)\n",
        "        return corrupted_x\n",
        "\n",
        "    def decoder(self, x):\n",
        "        h2 = self.fc2(x)\n",
        "        return h2\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.noiser(x)\n",
        "        encode = self.encoder(out)\n",
        "        decode = self.decoder(encode)\n",
        "        return encode, decode\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.0, max_len=16):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(1), :].squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, feature_size=16, hidden_dim=32, num_layers=1, nhead=8, dropout=0.0, noise_level=0.01, noise_type = 'gaussian'):\n",
        "        super(Net, self).__init__()\n",
        "        self.auto_hidden = int(feature_size/2)\n",
        "        input_size = self.auto_hidden\n",
        "        self.pos = PositionalEncoding(d_model=input_size, max_len=input_size)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=input_size, nhead=nhead, dim_feedforward=hidden_dim, dropout=dropout)\n",
        "        self.cell = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "        self.autoencoder = Autoencoder(input_size=feature_size, hidden_dim=self.auto_hidden, noise_level=noise_level, noise_type=noise_type)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, feature_num, feature_size  = x.shape\n",
        "        encode, decode = self.autoencoder(x.reshape(batch_size, -1))# batch_size*seq_len\n",
        "        out = encode.reshape(batch_size, -1, self.auto_hidden)\n",
        "        out = self.pos(out)\n",
        "        out = out.reshape(1, batch_size, -1) # (1, batch_size, feature_size)\n",
        "        out = self.cell(out)\n",
        "        out = out.reshape(batch_size, -1) # (batch_size, hidden_dim)\n",
        "        out = self.linear(out)            # out shape: (batch_size, 1)\n",
        "\n",
        "        return out, decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWaBi8dY5ERN"
      },
      "outputs": [],
      "source": [
        "def train(lr=0.01, feature_size=8, hidden_dim=32, num_layers=1, nhead=8, weight_decay=0.0, EPOCH=1000, seed=0,\n",
        "         alpha=0.0, noise_level=0.0, dropout=0.0, metric='re', is_load_weights=True, noise_type = 'gaussian'):\n",
        "    score_list, result_list = [], []\n",
        "\n",
        "    for i in range(4):\n",
        "        name = Battery_list[i]\n",
        "        window_size = feature_size\n",
        "        train_x, train_y, train_data, test_data = get_train_test(Battery, name, window_size)\n",
        "        train_size = len(train_x)\n",
        "        print('sample size: {}'.format(train_size))\n",
        "\n",
        "        setup_seed(seed)\n",
        "        model = Net(feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead, dropout=dropout,\n",
        "                    noise_level=noise_level, noise_type=noise_type)\n",
        "        model = model.to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        '''\n",
        "        # save ramdom data for repetition\n",
        "        if torch.__version__.split('+')[0] >= '1.6.0':\n",
        "            torch.save(model.state_dict(), 'model_CALCE'+str(seed)+'.pth')\n",
        "        else:\n",
        "            torch.save(model.state_dict(), 'model_CALCE.pth', _use_new_zipfile_serialization=False)\n",
        "         '''\n",
        "\n",
        "        # load the random data generated by my device\n",
        "        if is_load_weights:\n",
        "            if torch.__version__.split('+')[0] >= '1.6.0':\n",
        "                model.load_state_dict(torch.load('initial_weights/model_CALCE.pth'))\n",
        "            else:\n",
        "                model.load_state_dict(torch.load('initial_weights/model_CALCE_1.5.0.pth'))\n",
        "\n",
        "        test_x = train_data.copy()\n",
        "        loss_list, y_ = [0], []\n",
        "        rmse, re, mae = 1, 1, 1\n",
        "        score_, score = [1], [1]\n",
        "        for epoch in range(EPOCH):\n",
        "            X = np.reshape(train_x/Rated_Capacity,(-1, 1, feature_size)).astype(np.float32)#(batch_size, seq_len, input_size)\n",
        "            y = np.reshape(train_y[:,-1]/Rated_Capacity,(-1,1)).astype(np.float32)# shape 为 (batch_size, 1)\n",
        "\n",
        "            X, y = torch.from_numpy(X).to(device), torch.from_numpy(y).to(device)\n",
        "            output, decode = model(X)\n",
        "            output = output.reshape(-1, 1)\n",
        "            loss = criterion(output, y) + alpha * criterion(decode, X.reshape(-1, feature_size))\n",
        "            optimizer.zero_grad()              # clear gradients for this training step\n",
        "            loss.backward()                    # backpropagation, compute gradients\n",
        "            optimizer.step()                   # apply gradients\n",
        "\n",
        "            if (epoch + 1)%10 == 0:\n",
        "                test_x = train_data.copy()\n",
        "                point_list = []\n",
        "                while (len(test_x) - len(train_data)) < len(test_data):\n",
        "                    x = np.reshape(np.array(test_x[-feature_size:])/Rated_Capacity,(-1, 1, feature_size)).astype(np.float32)\n",
        "                    x = torch.from_numpy(x).to(device) # (batch_size,feature_size=1,input_size)\n",
        "                    pred, _ = model(x)                 # pred shape (batch_size=1, feature_size=1)\n",
        "                    next_point = pred.data.cpu().numpy()[0,0] * Rated_Capacity\n",
        "                    test_x.append(next_point)     # The test values are added to the original sequence to continue to predict the next point\n",
        "                    point_list.append(next_point) # Saves the predicted value of the last point in the output sequence\n",
        "                y_.append(point_list)             # Save all the predicted values\n",
        "                loss_list.append(loss)\n",
        "                rmse = evaluation(y_test=test_data, y_predict=y_[-1])\n",
        "                mae = mean_squared_error(test_data,y_[-1])\n",
        "                re = relative_error(y_test=test_data, y_predict=y_[-1], threshold=Rated_Capacity*0.7)\n",
        "                #print('epoch:{:<2d} | loss:{:<6.4f} | RMSE:{:<6.4f} | RE:{:<6.4f}'.format(epoch, loss, rmse, re))\n",
        "            if metric == 're':\n",
        "                score = [re]\n",
        "            elif metric == 'rmse':\n",
        "                score = [rmse]\n",
        "            elif metric == 'mae':\n",
        "                score = [mae]\n",
        "            else:\n",
        "                score = [re, rmse]\n",
        "            if (loss < 0.001) and (score_[0] < score[0]):\n",
        "                break\n",
        "            score_ = score.copy()\n",
        "\n",
        "        score_list.append(score_)\n",
        "        result_list.append(y_[-1])\n",
        "    return score_list, result_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHABSecM5ERO"
      },
      "source": [
        "### optimal parameters of my device : Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz, Win10\n",
        "\n",
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.0\n",
        "alpha = 0.01\n",
        "lr = 0.0005    # learning rate\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "is_load_weights = False\n",
        "metric = 're'\n",
        "re mean: 0.0536\n",
        "\n",
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.0\n",
        "alpha = 0.01\n",
        "lr = 0.0005    # learning rate\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "is_load_weights = False\n",
        "metric = 'rmse'\n",
        "rmse mean: 0.0690"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vAQr0EQ5ERP"
      },
      "outputs": [],
      "source": [
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.0\n",
        "alpha = 0.01\n",
        "lr = 0.001    # learning rate\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "is_load_weights = False\n",
        "metric = 're'\n",
        "\n",
        "seed = 101\n",
        "SCORE = []\n",
        "print('seed:{}'.format(seed))\n",
        "score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                      weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                      noise_level=noise_level, metric=metric, is_load_weights=is_load_weights)\n",
        "print(np.array(score_list))\n",
        "print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "print('------------------------------------------------------------------')\n",
        "for s in score_list:\n",
        "    SCORE.append(s)\n",
        "\n",
        "print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.0\n",
        "alpha = 0.01\n",
        "lr = 0.001    # learning rate\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "is_load_weights = False\n",
        "metric = 'mae'\n",
        "# [1, 0.5, 0.1, 0.05, 0.01, 0.0]\n",
        "\n",
        "seed = 101\n",
        "SCORE = []\n",
        "for noise_level in [0.5, 0.01, 0.001]:\n",
        "  print('seed:{}, noise: {}'.format(seed, noise_level))\n",
        "  score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                        weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                        noise_level=noise_level, metric=metric, is_load_weights=is_load_weights)\n",
        "  print(np.array(score_list))\n",
        "  print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "  print('------------------------------------------------------------------')\n",
        "  for s in score_list:\n",
        "      SCORE.append(s)\n",
        "\n",
        "  print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))"
      ],
      "metadata": {
        "id": "otk-xi2lYU5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "is_load_weights = False\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.0\n",
        "num_layers = 1\n",
        "metric = 're'\n",
        "\n",
        "states = {}\n",
        "for lr in [0.0005]:\n",
        "    for hidden_dim in [32]:\n",
        "        for alpha in [0.01]:\n",
        "            for noise_level in [0.0, 0.1, 0.01, 1, 0.05]:\n",
        "                for noise_type in ['gaussian', 'speckle', 'poisson']:\n",
        "                  show_str = 'lr={}, num_layers={}, hidden_dim={}, alpha={}, noise_level={}, noise_type={}'.format(lr, num_layers, hidden_dim, alpha, noise_level, noise_type)\n",
        "                  print(show_str)\n",
        "                  SCORE = []\n",
        "                  for seed in range(5):\n",
        "                      print('seed:{}'.format(seed))\n",
        "                      score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                                            weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                                            noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, noise_type=noise_type)\n",
        "                      print(np.array(score_list))\n",
        "                      print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "                      print('------------------------------------------------------------------')\n",
        "                      for s in score_list:\n",
        "                          SCORE.append(s)\n",
        "\n",
        "                  print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))\n",
        "                  states[show_str] = np.mean(np.array(SCORE))\n",
        "                  print('===================================================================')\n",
        "\n",
        "min_key = min(states, key = states.get)\n",
        "print('optimal parameters: {}, result: {}'.format(min_key, states[min_key]))"
      ],
      "metadata": {
        "id": "ExFaCR-7biMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ByhKi05ERP"
      },
      "source": [
        "### use grid-search to determ parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dumeLJiS5ERP"
      },
      "outputs": [],
      "source": [
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "is_load_weights = False\n",
        "weight_decay = 0.0\n",
        "noise_level = 1\n",
        "num_layers = 1\n",
        "metric = 're'\n",
        "\n",
        "seeder = [101, 143, 420]\n",
        "\n",
        "states = {}\n",
        "for lr in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
        "    for hidden_dim in [16, 32, 64]:\n",
        "        for alpha in [1e-4, 1e-3, 1e-2]:\n",
        "              for noise_type in ['gaussian', 'speckle', 'poisson', 'uniform']:\n",
        "                show_str = 'lr={}, num_layers={}, hidden_dim={}, alpha={}, noise_level={}, noise_type={}'.format(lr, num_layers, hidden_dim, alpha, noise_level, noise_type)\n",
        "                print(show_str)\n",
        "                SCORE = []\n",
        "                for seed in range(3):\n",
        "                    print('seed:{}'.format(seeder[seed]))\n",
        "                    score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                                          weight_decay=weight_decay, EPOCH=EPOCH, seed=seeder[seed], dropout=dropout, alpha=alpha,\n",
        "                                          noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, noise_type=noise_type)\n",
        "                    print(np.array(score_list))\n",
        "                    print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "                    print('------------------------------------------------------------------')\n",
        "                    for s in score_list:\n",
        "                        SCORE.append(s)\n",
        "\n",
        "                print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))\n",
        "                states[show_str] = np.mean(np.array(SCORE))\n",
        "                print('===================================================================')\n",
        "\n",
        "min_key = min(states, key = states.get)\n",
        "print('optimal parameters: {}, result: {}'.format(min_key, states[min_key]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import logging\n",
        "\n",
        "Rated_Capacity = 1.1\n",
        "window_size = 64\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 500\n",
        "nhead = 16\n",
        "is_load_weights = False\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.01\n",
        "num_layers = 1\n",
        "metric = 're'\n",
        "\n",
        "seeder = [101, 143, 420]\n",
        "\n",
        "def thread_function(name, SCORE, show_str, states, lr=0.01, feature_size=8, hidden_dim=32, num_layers=1, nhead=8, weight_decay=0.0, EPOCH=1000, seed=0,\n",
        "         alpha=0.0, noise_level=0.0, dropout=0.0, metric='re', is_load_weights=True, noise_type = 'gaussian'):\n",
        "    print(\"Thread %s: starting\", name)\n",
        "    for seed in range(3):\n",
        "        print('seed:{}'.format(seeder[seed]))\n",
        "        score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                              weight_decay=weight_decay, EPOCH=EPOCH, seed=seeder[seed], dropout=dropout, alpha=alpha,\n",
        "                              noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, noise_type=noise_type)\n",
        "        print(np.array(score_list))\n",
        "        print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "        print('------------------------------------------------------------------')\n",
        "        for s in score_list:\n",
        "            SCORE.append(s)\n",
        "    print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))\n",
        "    states[show_str] = np.mean(np.array(SCORE))\n",
        "    print('===================================================================')\n",
        "    print(\"Thread %s: finishing\", name)\n",
        "\n",
        "states = {}\n",
        "for lr in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
        "    for hidden_dim in [16, 32, 64]:\n",
        "        for alpha in [1e-4, 1e-3, 1e-2]:\n",
        "              threaders = []\n",
        "              for noise_type in ['gaussian', 'speckle', 'poisson', 'uniform']:\n",
        "                show_str = 'lr={}, num_layers={}, hidden_dim={}, alpha={}, noise_level={}, noise_type={}'.format(lr, num_layers, hidden_dim, alpha, noise_level, noise_type)\n",
        "                print(show_str)\n",
        "                SCORE = []\n",
        "                # x = threading.Thread(target=thread_function, args=(f\"{noise_type}_threader\", SCORE, show_str, states, lr, feature_size, hidden_dim, num_layers, nhead,\n",
        "                #                           weight_decay, EPOCH, seeder[seed], dropout, alpha,\n",
        "                #                           noise_level, metric, is_load_weights, noise_type, ))\n",
        "                # x.start()\n",
        "                # threaders.append(x)\n",
        "                for seed in range(3):\n",
        "                    print('seed:{}'.format(seeder[seed]))\n",
        "                    score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                                          weight_decay=weight_decay, EPOCH=EPOCH, seed=seeder[seed], dropout=dropout, alpha=alpha,\n",
        "                                          noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, noise_type=noise_type)\n",
        "                    print(np.array(score_list))\n",
        "                    print(metric + ': {:<6.4f}'.format(np.mean(np.array(score_list))))\n",
        "                    print('------------------------------------------------------------------')\n",
        "                    for s in score_list:\n",
        "                        SCORE.append(s)\n",
        "\n",
        "              # for thread in threaders:\n",
        "              #   thread.join()\n",
        "\n",
        "                print(metric + ' mean: {:<6.4f}'.format(np.mean(np.array(SCORE))))\n",
        "                states[show_str] = np.mean(np.array(SCORE))\n",
        "                print('===================================================================')\n",
        "\n",
        "min_key = min(states, key = states.get)\n",
        "print('optimal parameters: {}, result: {}'.format(min_key, states[min_key]))"
      ],
      "metadata": {
        "id": "AAy9UnfZ6tu-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}