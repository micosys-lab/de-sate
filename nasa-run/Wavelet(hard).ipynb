{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OtqDaVBhJPw",
        "outputId": "682c9e45-ac28-488b-dfb3-474521df7507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import transformers\n",
        "%matplotlib inline\n",
        "\n",
        "from math import sqrt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "oqUPCRUmh5NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "from scipy.signal import find_peaks\n",
        "import scipy.io\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "kDHyLlYdh7cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Cg56evfgh_LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert str to datatime\n",
        "def convert_to_time(hmm):\n",
        "    year, month, day, hour, minute, second = int(hmm[0]), int(hmm[1]), int(hmm[2]), int(hmm[3]), int(hmm[4]), int(hmm[5])\n",
        "    return datetime(year=year, month=month, day=day, hour=hour, minute=minute, second=second)\n",
        "\n",
        "\n",
        "# load .mat data\n",
        "def loadMat(matfile):\n",
        "    data = scipy.io.loadmat(matfile)\n",
        "    filename = matfile.split(\"/\")[-1].split(\".\")[0]\n",
        "    col = data[filename]\n",
        "    col = col[0][0][0][0]\n",
        "    size = col.shape[0]\n",
        "\n",
        "    data = []\n",
        "    for i in range(size):\n",
        "        k = list(col[i][3][0].dtype.fields.keys())\n",
        "        d1, d2 = {}, {}\n",
        "        if str(col[i][0][0]) != 'impedance':\n",
        "            for j in range(len(k)):\n",
        "                t = col[i][3][0][0][j][0];\n",
        "                l = [t[m] for m in range(len(t))]\n",
        "                d2[k[j]] = l\n",
        "        d1['type'], d1['temp'], d1['time'], d1['data'] = str(col[i][0][0]), int(col[i][1][0]), str(convert_to_time(col[i][2][0])), d2\n",
        "        data.append(d1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# get capacity data\n",
        "def getBatteryCapacity(Battery):\n",
        "    cycle, capacity = [], []\n",
        "    i = 1\n",
        "    for Bat in Battery:\n",
        "        if Bat['type'] == 'discharge':\n",
        "            capacity.append(Bat['data']['Capacity'][0])\n",
        "            cycle.append(i)\n",
        "            i += 1\n",
        "    return [cycle, capacity]\n",
        "\n",
        "\n",
        "# get the charge data of a battery\n",
        "def getBatteryValues(Battery, Type='charge'):\n",
        "    data=[]\n",
        "    for Bat in Battery:\n",
        "        if Bat['type'] == Type:\n",
        "            data.append(Bat['data'])\n",
        "    return data"
      ],
      "metadata": {
        "id": "aFf0ePj_iHsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Battery_list = ['B0005', 'B0006', 'B0007', 'B0018']\n",
        "dir_path = 'datasets/NASA/'\n",
        "\n",
        "Battery = {}\n",
        "for name in Battery_list:\n",
        "    print('Load Dataset ' + name + '.mat ...')\n",
        "    path = dir_path + name + '.mat'\n",
        "    data = loadMat(path)\n",
        "    Battery[name] = getBatteryCapacity(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY4SviJiiLqr",
        "outputId": "1cbffff6-7b9e-4ac8-f144-4c85f61777f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Dataset B0005.mat ...\n",
            "Load Dataset B0006.mat ...\n",
            "Load Dataset B0007.mat ...\n",
            "Load Dataset B0018.mat ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def wavelet_denoise(data, wavelet='db4', threshold=0.1):\n",
        "    #  wavelet decomposition\n",
        "    coeffs = pywt.wavedec(data, wavelet)\n",
        "\n",
        "    #  threshold for denoising\n",
        "    coeffs = [pywt.threshold(c, threshold, mode='hard') for c in coeffs]\n",
        "\n",
        "    # Reconstruct the denoised signal\n",
        "    denoised_data = pywt.waverec(coeffs, wavelet)\n",
        "\n",
        "    return denoised_data\n",
        "\n",
        "\n",
        "def build_sequences(text, window_size):\n",
        "    #text:list of capacity\n",
        "    x, y = [],[]\n",
        "    for i in range(len(text) - window_size):\n",
        "        sequence = text[i:i+window_size]\n",
        "        target = text[i+1:i+1+window_size]\n",
        "\n",
        "        x.append(sequence)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "def split_dataset(data_sequence, train_ratio=0.0, capacity_threshold=0.0):\n",
        "    if capacity_threshold > 0:\n",
        "        max_capacity = max(data_sequence)\n",
        "        capacity = max_capacity * capacity_threshold\n",
        "        point = [i for i in range(len(data_sequence)) if data_sequence[i] < capacity]\n",
        "    else:\n",
        "        point = int(train_ratio + 1)\n",
        "        if 0 < train_ratio <= 1:\n",
        "            point = int(len(data_sequence) * train_ratio)\n",
        "    train_data, test_data = data_sequence[:point], data_sequence[point:]\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "def get_train_test(data_dict, name, window_size=8, wavelet='db4', threshold=0.1):\n",
        "    data_sequence = data_dict[name][1]\n",
        "    data_sequence = wavelet_denoise(data_sequence, wavelet, threshold)\n",
        "\n",
        "    train_data, test_data = data_sequence[:window_size+1], data_sequence[window_size+1:]\n",
        "    train_x, train_y = build_sequences(text=train_data, window_size=window_size)\n",
        "\n",
        "    for k, v in data_dict.items():\n",
        "        if k != name:\n",
        "            data_sequence = wavelet_denoise(v[1], wavelet, threshold)\n",
        "            data_x, data_y = build_sequences(text=data_sequence, window_size=window_size)\n",
        "            train_x, train_y = np.r_[train_x, data_x], np.r_[train_y, data_y]\n",
        "\n",
        "    return train_x, train_y, list(train_data), list(test_data)\n",
        "\n",
        "\n",
        "def relative_error(y_test, y_predict, threshold):\n",
        "    true_re, pred_re = len(y_test), 0\n",
        "    for i in range(len(y_test)-1):\n",
        "        if y_test[i] <= threshold >= y_test[i+1]:\n",
        "            true_re = i - 1\n",
        "            break\n",
        "    for i in range(len(y_predict)-1):\n",
        "        if y_predict[i] <= threshold:\n",
        "            pred_re = i - 1\n",
        "            break\n",
        "    return abs(true_re - pred_re)/true_re\n",
        "\n",
        "\n",
        "def evaluation(y_test, y_predict):\n",
        "    mse = mean_squared_error(y_test, y_predict)\n",
        "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
        "    mae = mean_absolute_error(y_test,y_predict)\n",
        "    return rmse , mae\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "RfP7rfZqiO0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size=16, hidden_dim=8, noise_level=0.01):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.input_size, self.hidden_dim, self.noise_level = input_size, hidden_dim, noise_level\n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "        self.fc2 = nn.Linear(self.hidden_dim, self.input_size)\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = self.fc1(x)\n",
        "        h1 = F.relu(x)\n",
        "        return h1\n",
        "\n",
        "    def mask(self, x):\n",
        "        corrupted_x = x + self.noise_level * torch.randn_like(x)\n",
        "        return corrupted_x\n",
        "\n",
        "    def decoder(self, x):\n",
        "        h2 = self.fc2(x)\n",
        "        return h2\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mask(x)\n",
        "        encode = self.encoder(out)\n",
        "        decode = self.decoder(encode)\n",
        "        return encode, decode\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.0, max_len=16):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(1), :].squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, feature_size=16, hidden_dim=32, num_layers=1, nhead=8, dropout=0.0, noise_level=0.01, wavelet='db4', threshold=0.1):\n",
        "        super(Net, self).__init__()\n",
        "        self.auto_hidden = int(feature_size/2)\n",
        "        input_size = self.auto_hidden\n",
        "        self.pos = PositionalEncoding(d_model=input_size, max_len=input_size)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=input_size, nhead=nhead, dim_feedforward=hidden_dim, dropout=dropout)\n",
        "        self.cell = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "        self.autoencoder = Autoencoder(input_size=feature_size, hidden_dim=self.auto_hidden, noise_level=noise_level)\n",
        "        self.wavelet = wavelet\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, feature_num, feature_size = x.shape\n",
        "\n",
        "        x = x.cpu().numpy()\n",
        "\n",
        "\n",
        "        denoised_x = [torch.from_numpy(wavelet_denoise(x[i, 0, :], self.wavelet, self.threshold)).to(device) for i in range(batch_size)]\n",
        "\n",
        "\n",
        "        denoised_x = torch.stack(denoised_x)\n",
        "\n",
        "\n",
        "        denoised_x = denoised_x.view(batch_size, feature_num, feature_size)\n",
        "        encode, decode = self.autoencoder(denoised_x.reshape(batch_size, -1))\n",
        "\n",
        "        out = encode.reshape(batch_size, -1, self.auto_hidden)\n",
        "        out = self.pos(out)\n",
        "        out = out.reshape(1, batch_size, -1)  # (1, batch_size, feature_size)\n",
        "        out = self.cell(out)\n",
        "        out = out.reshape(batch_size, -1)  # (batch_size, hidden_dim)\n",
        "        out = self.linear(out)  # out shape: (batch_size, 1)\n",
        "\n",
        "        return out, decode"
      ],
      "metadata": {
        "id": "1rnBZ2V5iSAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(lr=0.01, feature_size=8, hidden_dim=32, num_layers=1, nhead=8, weight_decay=0.0, EPOCH=1000, seed=0,\n",
        "         alpha=0.0, noise_level=0.0, dropout=0.0, metric='re', is_load_weights=True, wavelet='db4', threshold=0.1):\n",
        "    score_list, result_list = [], []\n",
        "    setup_seed(seed)\n",
        "    for i in range(4):\n",
        "        name = Battery_list[i]\n",
        "        window_size = feature_size\n",
        "        train_x, train_y, train_data, test_data = get_train_test(Battery, name, window_size)\n",
        "        train_size = len(train_x)\n",
        "\n",
        "        # Apply wavelet denoising to the training data\n",
        "        train_x = np.array([wavelet_denoise(train_x[i], wavelet, threshold) for i in range(train_size)])\n",
        "\n",
        "        model = Net(feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead, dropout=dropout,\n",
        "                    noise_level=noise_level, wavelet=wavelet, threshold=threshold)\n",
        "        model = model.to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        if is_load_weights:\n",
        "            if torch.__version__.split('+')[0] >= '1.6.0':\n",
        "                model.load_state_dict(torch.load('initial_weights/model_NASA.pth'))\n",
        "            else:\n",
        "                model.load_state_dict(torch.load('initial_weights/model_NASA_1.5.0.pth'))\n",
        "\n",
        "        test_x = train_data.copy()\n",
        "        loss_list, y_ = [0], []\n",
        "        rmse, re , mae = 1, 1 , 1\n",
        "        score_, score = [1],[1]\n",
        "        for epoch in range(EPOCH):\n",
        "            X = np.reshape(train_x/Rated_Capacity, (-1, 1, feature_size)).astype(np.float32)\n",
        "            y = np.reshape(train_y[:,-1]/Rated_Capacity, (-1, 1)).astype(np.float32)\n",
        "\n",
        "            X, y = torch.from_numpy(X).to(device), torch.from_numpy(y).to(device)\n",
        "            output, decode = model(X)\n",
        "            output = output.reshape(-1, 1)\n",
        "            loss = criterion(output, y) + alpha * criterion(decode, X.reshape(-1, feature_size))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                test_x = train_data.copy()\n",
        "                point_list = []\n",
        "                while (len(test_x) - len(train_data)) < len(test_data):\n",
        "                    x = np.reshape(np.array(test_x[-feature_size:])/Rated_Capacity, (-1, 1, feature_size)).astype(np.float32)\n",
        "                    x = torch.from_numpy(x).to(device)\n",
        "                    pred, _ = model(x)\n",
        "                    next_point = pred.data.cpu().numpy()[0,0] * Rated_Capacity\n",
        "                    test_x.append(next_point)\n",
        "                    point_list.append(next_point)\n",
        "                y_.append(point_list)\n",
        "\n",
        "                loss_list.append(loss)\n",
        "                rmse = evaluation(y_test=test_data, y_predict=y_[-1])\n",
        "                re = relative_error(y_test=test_data, y_predict=y_[-1], threshold=Rated_Capacity*0.7)\n",
        "\n",
        "            if metric == 're':\n",
        "                score = [re]\n",
        "            elif metric == 'rmse':\n",
        "                score = [rmse]\n",
        "            elif metric == 'mae':\n",
        "                score = [mae]\n",
        "            else:\n",
        "                score = [re, rmse,mae]\n",
        "            if (loss < 1e-3) and (score_[0] < score[0]):\n",
        "                break\n",
        "            score_ = score.copy()\n",
        "\n",
        "        score_list.append(score_)\n",
        "        result_list.append(y_[-1])\n",
        "    return score_list, result_list\n"
      ],
      "metadata": {
        "id": "p0gkq0dJiWn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rated_Capacity = 2.0\n",
        "window_size = 16\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 2000\n",
        "nhead = 8\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.00\n",
        "alpha = 1e-6\n",
        "is_load_weights = False\n",
        "metric = 're'\n",
        "wavelet = 'db4'\n",
        "threshold = 0.01\n",
        "\n",
        "re_means = []\n",
        "\n",
        "for seed in range(5):\n",
        "    SCORE = []\n",
        "    print('seed:{}'.format(seed))\n",
        "    score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                          weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                          noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, wavelet=wavelet, threshold=threshold)\n",
        "    print(np.array(score_list))\n",
        "    for s in score_list:\n",
        "        SCORE.append(s)\n",
        "    print('------------------------------------------------------------------')\n",
        "    re_mean = np.mean(np.array(SCORE))\n",
        "    print(metric + ' mean for seed {}: {:<6.4f}'.format(seed, re_mean))\n",
        "    re_means.append(re_mean)  # Append the mean 're' score for this seed\n",
        "\n",
        "# Calculate the total mean 're' score across all seeds\n",
        "total_re_mean = np.mean(np.array(re_means))\n",
        "print('Total ' + metric + ' mean across all seeds: {:<6.4f}'.format(total_re_mean))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKza2tzhiZ5D",
        "outputId": "b625c428-d827-4b28-c58d-7b639edf41a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed:0\n",
            "[[0.04761905]\n",
            " [0.58695652]\n",
            " [0.1589404 ]\n",
            " [0.22727273]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 0: 0.2552\n",
            "seed:1\n",
            "[[0.33333333]\n",
            " [0.45652174]\n",
            " [0.22516556]\n",
            " [0.10227273]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 1: 0.2793\n",
            "seed:2\n",
            "[[0.07619048]\n",
            " [0.16304348]\n",
            " [0.34437086]\n",
            " [0.31818182]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 2: 0.2254\n",
            "seed:3\n",
            "[[0.14285714]\n",
            " [0.60869565]\n",
            " [0.04635762]\n",
            " [0.125     ]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 3: 0.2307\n",
            "seed:4\n",
            "[[0.02857143]\n",
            " [0.55434783]\n",
            " [0.0794702 ]\n",
            " [0.15909091]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 4: 0.2054\n",
            "Total re mean across all seeds: 0.2392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rated_Capacity = 2.0\n",
        "window_size = 16\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 2000\n",
        "nhead = 8\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.00\n",
        "alpha = 1e-6\n",
        "is_load_weights = False\n",
        "metric = 're'\n",
        "wavelet = 'db4'\n",
        "threshold = 0.001\n",
        "\n",
        "re_means = []\n",
        "\n",
        "for seed in range(5):\n",
        "    SCORE = []\n",
        "    print('seed:{}'.format(seed))\n",
        "    score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                          weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                          noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, wavelet=wavelet, threshold=threshold)\n",
        "    print(np.array(score_list))\n",
        "    for s in score_list:\n",
        "        SCORE.append(s)\n",
        "    print('------------------------------------------------------------------')\n",
        "    re_mean = np.mean(np.array(SCORE))\n",
        "    print(metric + ' mean for seed {}: {:<6.4f}'.format(seed, re_mean))\n",
        "    re_means.append(re_mean)  # Append the mean 're' score for this seed\n",
        "\n",
        "# Calculate the total mean 're' score across all seeds\n",
        "total_re_mean = np.mean(np.array(re_means))\n",
        "print('Total ' + metric + ' mean across all seeds: {:<6.4f}'.format(total_re_mean))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSw7klemkgtR",
        "outputId": "60fd46ab-dc0b-4e21-b513-8391169fa80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed:0\n",
            "[[0.01904762]\n",
            " [0.58695652]\n",
            " [0.1589404 ]\n",
            " [0.21590909]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 0: 0.2452\n",
            "seed:1\n",
            "[[0.33333333]\n",
            " [0.45652174]\n",
            " [0.22516556]\n",
            " [0.10227273]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 1: 0.2793\n",
            "seed:2\n",
            "[[0.11428571]\n",
            " [0.08695652]\n",
            " [0.34437086]\n",
            " [0.31818182]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 2: 0.2159\n",
            "seed:3\n",
            "[[0.14285714]\n",
            " [0.60869565]\n",
            " [0.04635762]\n",
            " [0.11363636]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 3: 0.2279\n",
            "seed:4\n",
            "[[0.04761905]\n",
            " [0.55434783]\n",
            " [0.0794702 ]\n",
            " [0.23863636]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 4: 0.2300\n",
            "Total re mean across all seeds: 0.2397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rated_Capacity = 2.0\n",
        "window_size = 16\n",
        "feature_size = window_size\n",
        "dropout = 0.0\n",
        "EPOCH = 2000\n",
        "nhead = 8\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "weight_decay = 0.0\n",
        "noise_level = 0.00\n",
        "alpha = 1e-6\n",
        "is_load_weights = False\n",
        "metric = 're'\n",
        "wavelet = 'db4'\n",
        "threshold = 0.05\n",
        "\n",
        "re_means = []\n",
        "\n",
        "for seed in range(5):\n",
        "    SCORE = []\n",
        "    print('seed:{}'.format(seed))\n",
        "    score_list, _ = train(lr=lr, feature_size=feature_size, hidden_dim=hidden_dim, num_layers=num_layers, nhead=nhead,\n",
        "                          weight_decay=weight_decay, EPOCH=EPOCH, seed=seed, dropout=dropout, alpha=alpha,\n",
        "                          noise_level=noise_level, metric=metric, is_load_weights=is_load_weights, wavelet=wavelet, threshold=threshold)\n",
        "    print(np.array(score_list))\n",
        "    for s in score_list:\n",
        "        SCORE.append(s)\n",
        "    print('------------------------------------------------------------------')\n",
        "    re_mean = np.mean(np.array(SCORE))\n",
        "    print(metric + ' mean for seed {}: {:<6.4f}'.format(seed, re_mean))\n",
        "    re_means.append(re_mean)  # Append the mean 're' score for this seed\n",
        "\n",
        "# Calculate the total mean 're' score across all seeds\n",
        "total_re_mean = np.mean(np.array(re_means))\n",
        "print('Total ' + metric + ' mean across all seeds: {:<6.4f}'.format(total_re_mean))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgwU0yRPmmRF",
        "outputId": "94296454-a0ba-4555-8ccc-f3f9f094b3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed:0\n",
            "[[0.05714286]\n",
            " [0.58695652]\n",
            " [0.1589404 ]\n",
            " [0.21590909]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 0: 0.2547\n",
            "seed:1\n",
            "[[0.33333333]\n",
            " [0.45652174]\n",
            " [0.22516556]\n",
            " [0.10227273]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 1: 0.2793\n",
            "seed:2\n",
            "[[0.07619048]\n",
            " [0.07608696]\n",
            " [0.34437086]\n",
            " [0.31818182]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 2: 0.2037\n",
            "seed:3\n",
            "[[0.14285714]\n",
            " [0.60869565]\n",
            " [0.04635762]\n",
            " [0.11363636]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 3: 0.2279\n",
            "seed:4\n",
            "[[0.02857143]\n",
            " [0.55434783]\n",
            " [0.0794702 ]\n",
            " [0.19318182]]\n",
            "------------------------------------------------------------------\n",
            "re mean for seed 4: 0.2139\n",
            "Total re mean across all seeds: 0.2359\n"
          ]
        }
      ]
    }
  ]
}